
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EDITORIAL SECTION
%
\documentclass{PSAIE}%

\sloppy
\begin{document}%
\PSAIEHeadFirst{10}{1}{1}{3}%
%
% END OF EDITORIAL SECTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Please give a short title for the running head
\fancyhead[CO]{\PSAIEheader{Temporary title}} % TODO: Make actual title
% Short list of authors for the running head
\fancyhead[CE]{\PSAIEheader{Bal\'azs Bolyki, L\'aszl\'o \'Arvai and Dr. Szilvia \'Arvai-Homolya}}
\fancyfoot{}

\noindent\PSAIEtitle{Temporary title} % TODO: Make actual title

\noindent\PSAIEauthor{Bal\'azs Bolyki}
{University of Miskolc, Hungary\\[0pt] Informatics Institute}
{bolyki@iit.uni-miskolc.hu}

\noindent\PSAIEauthor{L\'aszl\'o \'Arvai}
{University of Miskolc, Hungary\\[0pt] Informatics Institute}
{arvai.laszlo@iit.uni-miskolc.hu}

\noindent\PSAIEauthor{Dr. Szilvia \'Arvai-Homolya}
{University of Miskolc, Hungary\\[0pt] Mathematics Institute}
{mathszil@uni-miskolc.hu}

\noindent\PSAIEreceived{\today}

\noindent\PSAIEabstract{This paper is a template for those authors
      who wish to prepare their manuscript to be published in
      \emph{Production Systems and Information Engineering} by using the
      \emph{amsart} document class. You can reedit the text of this
      paper and the corresponding \emph{bib} file in order to obtain
      your manuscript.}

\noindent\PSAIEkey{dataset, grapevine}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introductions}
Robotization of grapevine pruning has become an area of interest in agriculture recently
\cite{botterill2017robot}, \cite{fernandes2021grapevine}, \cite{katyara2020reproducible}, since
tools for executing such a task are now available. Proper pruning requires expertise, and it is
a time consuming activity, resulting in expensive human workforce. Consequently, robotization is
a viable and relevant alternative.

The pruning of grapevine means the removal of young, wooden canes of the plant, during the dormant session,
when the green parts are no longer present.
One of the subtasks of grapevine pruning is the reconstruction of the plant, based on images made by
one or multiple cameras, mounted on the robot. After plant reconstruction, the system can make decisions
as to where pruning has to be performed. Convolutional neural networks are available to do
object detection and localization on images \cite{glenn_jocher_2021_5563715}, \cite{matterport_maskrcnn_2017},
\cite{liu2016ssd}. However, such approaches require great amounts of training data. Creating a training
dataset of sufficient size and quality is laborous, and topic specific datasets are usually not available.
Also, existing neural networks do not provide their output in a proper format; at the time of writing,
there is no neural network with an output format, which could be directly utilized for pruning point
detection.

The desired output format of the plant reconstruction is a semantic graph, where graph nodes are parts
of the grapevine, and graph edges are connections between the parts. We aim to extend our existing
dataset towards such a graph format. In this paper, we achieve two goals. First, generating and
extending an existing, topic specific dataset, namely a bounding box based dataset created on grapevines.
Second, we use the current
bounding box data to retrieve more information on the grapevine structure, and convert the available
information to a more favorable format. In later sections we propose a methodology for generating a
new dataset algorithmically, based on the original dataset, using area specific knowledge on the
grapevine, while requiring as little human intervention as possible. We also demonstrate how well a
neural network performs on purely machine generated data.

\section{Survey} \label{sec_survey}
Multiple papers address the issue of automated grapevine pruning. There are descriptions of complete,
functioning robot systems \cite{botterill2017robot}, and subtask descriptions of smaller scope
\cite{goesmannai}, \cite{fernandes2021grapevine}, \cite{katyara2020reproducible}.

When robotizing grapevine pruning, plant anatomy detection needs to be addressed. The thesis
\cite{white_background_grape} uses a purely algorithmic approach, analysing the grapevine plant
in front of a white background. However, taking images on grapevine plantation with white background
is problematic -- the author of the thesis took the pictures indoor. Background removal could also be
done by using the robot itself to block vision. In \cite{botterill2017robot} the background is not
visible, because the robot moves over the row grapevines and covers the plants in its U shaped form;
however, such a construct is very large and hard to transport.

In \cite{you2021semantics} robotic pruning of cherry trees is based on information retrieved by a
semantic segmentation neural network, then converted to skeleton format. Other
agricultural works use semantic or instance segmentation -- the paper \cite{chen2021semantic} uses semantic
segmentation for detecting apple trees, while \cite{santos2020grape} uses instance segmentation to count
grapes.

Authors addressing pruning point determination work on data in graph format \cite{goesmannai}, which is best
resembled by the skeleton format. Though skeleton format is desired for the output of the detector system,
we found no papers describing such neural networks, which directly returns skeletons for grapevine.
It is more viable to retrieve skeleton data, based on \cite{you2021semantics} semantic segmentation networks.

\section{Task description} \label{sec_task_description}
In this paper we describe a continuation of the thesis \cite{bolyki_2021}, where a bounding box based training
dataset was created, and the YOLO (You Only Look Once) neural network was trained
\cite{glenn_jocher_2021_5563715}.
A bounding box based dataset can be created relatively quickly, but it does not fit the task of pruning
point detection well. However, results retrieved in bounding box format are reliable, and could be utilized
to attain the desired information in favorable format, thereby also extending our dataset to contain the
attained information.

We have access to a large set of images taken on a grapevine plantation, with the usage of a white screen
for background, and we also have images without any white background at all. One of the images with
white background is presented on Figure \ref{fig_grapevine_image}.
We make use of the original \cite{bolyki_2021} trained neural network to create a more desired
format for representing grapevine detections. The original format not only uses bounding boxes for
representation, but only handles four different classes of grapevine parts:
\begin{enumerate}
      \item \textbf{trunk},
      \item \textbf{cordon} -- the old, thich part of the grapevine, running on the trellis wires horizontally,
      \item \textbf{arm} -- old, usually vertical branches, providing a base for canes to grow,
      \item \textbf{node} -- young proturbances on the canes organs supporting multiple buds
            (grapevine buds are complex).
\end{enumerate}

\begin{figure}[h]
      \centering
      \includegraphics[scale=0.08]{images/grapevine_image.jpg}
      \caption{Grapevine image}
      \label{fig_grapevine_image}
\end{figure}

Parts of the grapevine are represented on Figure \ref{fig_grapevine_structure}. It is best to further clarify
the meaning of node, bud, cane, internodium. Canes are young -- one year old -- wooden branches of the
grapevine, which consist of nodes -- spherical proturbances --, and internodiums -- straight woods connecting
the nodes. Buds can yield shoots (canes before lignification -- turning to wood), leaves, tendrils, flowers,
and they grow on nodes. To determine pruning points we need to know where are the canes, where are their nodes,
where they start -- do they grow from arms, cordons or the trunk, and how many canes grows from a single arm.

\begin{figure}[h]
      \centering
      \includegraphics[scale=0.7]{images/grapevine_structure.png}
      \caption{Grapevine structure \cite{hellman2003grapevine}}
      \label{fig_grapevine_structure}
\end{figure}

By extending the available dataset we mean multiple things.
\begin{enumerate}
      \item The available dataset could be extended purely in quantity. Since the accuracy of a neural network
            depends greatly on both the size and quality of the dataset, this extension is valuable.
            By running the detection script of the YOLO neural network on a large set of new images,
            we attain great amounts of new training images. However, these almost always require
            manual correction.
      \item We extend the dataset by adding a new class to the original four, which could be named \textit{cane}
            or \textit{internodium} depending on the extension format. This requires algorithmical detection of
            objects of the new class.
      \item We extend the dataset by adding new logical formats, meaning we use the original bounding box
            detections to create both skeleton and semantic segmentation datasets.
\end{enumerate}

\section{Internodium detection} \label{sec_internodium_detection}
Internodium detection is performed on pictures taken on grapevine plantations. On these images, white
background was used -- allowing us more operations on the grapevine, such as segmentation, background
switching and building of canes or detecting internodiums.

Detection of internodiums is performed by building canes, based on the nodes found by the pretrained YOLO
neural network \cite{bolyki_2021}, \cite{glenn_jocher_2021_5563715}. The pretrained YOLO network is used
to retrieve the bounding boxes representing the trunks, cordons, arms and nodes on the image. Figure
\ref{fig_grapevine_YOLO}. represents one of the outputs of the YOLO network.

\begin{figure}[h]
      \centering
      \includegraphics[scale=0.33]{images/grapevine_yolo.png}
      \caption{Grapevine detections \cite{hellman2003grapevine}}
      \label{fig_grapevine_YOLO}
\end{figure}

After the starting bounding box detections are retrieved, the steps of internodium detection are the following:

\begin{enumerate}
      \item Create color masks for the young parts of the grapevine -- internodiums, nodes.
      \item Build the cane starting from a specific node.
      \item Store the connections between the nodes of the cane, thereby storing the internodiums.
\end{enumerate}

In this section we describe these steps in more detail.

\subsection{Create color masks} \label{sec_create_color_masks}
Since the pictures taken on the grapevine plantation have white backgrounds, separating the grapevine
from the background by color is perfectly viable. Also, it is possible to separate the older and the
younger parts of the grapevine from each other. In order to do so, we make use of the OpenCV
(Open Source Computer Vision)
library \cite{opencv_library}. The library contains a large set of optimized image processing and computer
vision algorithms. We use it for loading images, converting colors, executing morphological operations.

To separate the younger and older parts of the image from the background, we first convert the images
to HSV color space (Hue-Saturation-Value) from OpenCV's default (BGR -- Blue-Green-Red). Based on the
HSV value of pixels we generate binary masks for both young and old parts of the cane, where the size
of the mask matches the image, and each field of the mask is set to true (represented by the number 255,
since OpenCV does not physically support true binary masks) if its color is within a specified range.

The ranges specified for the young and the old parts are the following:

\begin{itemize}
      \item \textbf{Young part (cane)}: $hs > 60 \wedge hv > 70$
      \item \textbf{Old part (arm, cordon, trunk)}: $hs > 10 \wedge hv <= 70$
\end{itemize}

\subsection{Build cane} \label{sec_build_cane}
In order to find connections between the nodes, we attempt to build canes on the image.

\subsection{Store connections} \label{sec_store_connections}

\section*{Acknowledgements}
\noindent
The authors express their gratitude to the XXX Institute at YYY for
their hospitality, etc.

\bibliographystyle{PSAIEbib}
\bibliography{citations}

\end{document}